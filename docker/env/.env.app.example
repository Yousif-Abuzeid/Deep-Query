APP_NAME="mini-rag"
APP_VERSION="0.1.0"

FILE_ALLOWED_TYPES=["text/plain", "application/pdf"]
FILE_MAX_SIZE=10  # 10 MB
FILE_DEFAULT_CHUNK_SIZE=512 # 512 KB


POSTGRES_USERNAME="postgres"
POSTGRES_PASSWORD="postgres"
POSTGRES_HOST="pgvector"
POSTGRES_PORT=5432
POSTGRES_MAIN_DATABASE="minirag"

# ============================= LLM CONFIGURATION =============================
GENERATION_BACKEND="GOOGLE_GENAI"  # Options: "openai", "cohere", "google_genai"
EMBEDDING_BACKEND="GOOGLE_GENAI"  # Options: "openai", "cohere", "google_genai"

COHERE_API_KEY="your_cohere_api_key"
OPENAI_API_KEY="ollama"
OPENAI_API_URL="http://localhost:11434/v1"

GENERATION_MODEL_ID_LITERAL=["gemma3:4b","gemini-2.5-flash","gpt-4o"]
GENERATION_MODEL_ID="gemini-2.5-flash"
EMBEDDING_MODEL_ID="text-embedding-004"

GOOGLE_GENAI_API_KEY="your_google_genai_api_key"
TAVILY_API_KEY="your_tavily_api_key"
EMBEDDING_MODEL_SIZE=768

INPUT_DEFAULT_MAX_CHARACTERS=10000
GENERATION_DEFAULT_MAX_TOKENS=2048
GENERATION_DEFAULT_TEMPERATURE=0.7

# ============================= DEEP RESEARCH CONFIGURATION =============================
MAX_CONCURRENT_RESEARCH_UNITS=3  # Number of parallel research tasks per iteration
MAX_RESEARCHER_ITERATIONS=3      # Maximum number of research cycles
# ============================= VECTOR DB CONFIGURATION =============================
VECTOR_DB_BACKEND_LITERAL=["QDRANT", "PGVECTOR"]
VECTOR_DB_DISTANCE_METHOD_LITERAL=["cosine", "dot"]
VECTOR_DB_BACKEND="PGVECTOR"  # Options: "QDRANT", "PGVECTOR"
VECTOR_DB_PATH="qdrant_db"
VECTOR_DB_DISTANCE_METHOD="cosine"  # Options: "COSINE", "DOT"
VECTOR_DB_PGVEC_INDEX_THRESHOLD=100  # Threshold to create index on pgvector vector column

# ============================= Template CONFIGURATION =============================
DEFAULT_LANG="en"
PRIMARY_LANG="en"


